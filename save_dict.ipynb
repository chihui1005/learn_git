{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/chihui/anaconda3/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from pattern.text.en import singularize\n",
    "import json, os, time, parser\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "import copy\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "import json, os, time, parser\n",
    "import _pickle as pickle\n",
    "\n",
    "#root = os.path.dirname(os.path.abspath(__file__))\n",
    "\n",
    "def log_conf():\n",
    "\n",
    "    # set up logging to file - see previous section for more details\n",
    "    log_file_path = os.path.join('/Users/ch/Documents/medical_entity_dict/modify_entity_dict/all_modify_info.log')\n",
    "    logging.basicConfig(level=logging.DEBUG, format='%(asctime)s %(name)-12s %(levelname)-8s %(message)s',\n",
    "                        datefmt='%m-%d %H:%M', filename=log_file_path, filemode='w')\n",
    "    # define a Handler which writes INFO messages or higher to the sys.stderr\n",
    "    #console = logging.StreamHandler()\n",
    "    #console.setLevel(logging.INFO)\n",
    "    # set a format which is simpler for console use\n",
    "    #formatter = logging.Formatter('%(name)-12s: %(levelname)-8s %(message)s')\n",
    "    # tell the handler to use this format\n",
    "    #console.setFormatter(formatter)\n",
    "    # add the handler to the root logger\n",
    "    #logging.getLogger('').addHandler(console)\n",
    "    # logger1 = logging.getLogger('ner_app.area1')\n",
    "\n",
    "def loads_pickle(map):\n",
    "    d_c = defaultdict(int)\n",
    "    d_s = defaultdict(int)\n",
    "    cate_name=open('/Users/ch/Documents/medical_entity_dict/modify_entity_dict/cate_name.dict','w')\n",
    "    synoyms_name=open('/Users/ch/Documents/medical_entity_dict/modify_entity_dict/synoyms_name.dict','w')\n",
    "    if os.path.exists(map):\n",
    "        fs = open(map, 'rb')\n",
    "        med_synonyms_name_dict, med_name_cate_dict = pickle.loads(fs.read())  # 使用loads反序列化\n",
    "#        print(med_synonyms_name_dict, med_name_cate_dict)\n",
    "\n",
    "    for k,synoyms in  med_name_cate_dict.items():\n",
    "        string = k + \":\" + synoyms + \"\\n\"\n",
    "\n",
    "        cate_name.write(string)\n",
    "\n",
    "        d_c[synoyms] +=1\n",
    "    for k,synoyms in  med_synonyms_name_dict.items():\n",
    "        string = k + \":\" + synoyms + \"\\n\"\n",
    "\n",
    "        synoyms_name.write(string)\n",
    "        d_s[synoyms] +=1\n",
    "\n",
    "\n",
    "    #print (med_name_cate_dict.items())\n",
    "    #print (d_c.items())\n",
    "    print (sorted(d_c.items(),key=lambda x:x[1], reverse=True))\n",
    "    #print (d_s.items())\n",
    "\n",
    "def gen_dict():\n",
    "    #with open(os.path.join(root, 'data/medical')) as f:\n",
    "    fl = open('/Users/ch/Documents/medical_entity_dict/modify_entity_dict/med_name_cate_dict.json','w')\n",
    "    with open('/Users/ch/Documents/medical_entity_dict/ten_entity_library/medical_entity_dict_v3.0.txt') as f:\n",
    "        m_e_d = []\n",
    "        for i in f.readlines():\n",
    "            try:\n",
    "                json_text = json.loads(i.strip())\n",
    "                m_e_d.append(json_text)\n",
    "            except ValueError:\n",
    "                logging.debug(\"json_loads err:{0}\".format(i))\n",
    "    # 存储name->cate,小写（就是category）\n",
    "    med_name_cate_dict = {}\n",
    "    # 存储name and synonyms -> name，小写（name:name，synonyms:name，值都name）\n",
    "    med_synonyms_name_dict = {}\n",
    "\n",
    "    ####\n",
    "    print (len(m_e_d))\n",
    "\n",
    "\n",
    "    #try:\n",
    "    for item in m_e_d:\n",
    "        #if item['name']!='3-Hydroxy-3-Methylglutaryl-Coa Lyase Deficiency':\n",
    "        if item[\"name\"].lower():\n",
    "            # 如果名字属于名ci，就保留.但如果是形容词，则判断name 是否包含‘，’，‘-’，如果是则保留\n",
    "            flag_name = pos_tag([item[\"name\"].lower()])[0][-1] in [\"NN\", \"NNS\", \"NNP\", \"NNPS\"]\\\n",
    "                or (pos_tag([item[\"name\"].lower()])[0][-1] in [\"JJ\"] and (',' in item['name'] or '-' in item['name']))   #化合物是形容词，保留了特殊符号的\n",
    "            if flag_name:\n",
    "#                if (item[\"name\"].lower())[-2:] != \"ta\":\n",
    "#                    name = singularize(item[\"name\"].lower())\n",
    "#                else:\n",
    "#                    name = item[\"name\"].lower()\n",
    "#                    \n",
    "#                med_name_cate_dict[name] = copy.copy(item[\"category\"].lower())\n",
    "#                med_synonyms_name_dict[name] = copy.copy(name)#建立同义词key与字典key的关联。即将字典name加入同义词中\n",
    "                med_name_cate_dict[item[\"name\"].lower().strip()] = copy.copy(item[\"category\"].lower())\n",
    "                med_synonyms_name_dict[item[\"name\"].lower().strip()] = copy.copy(item[\"name\"].lower().strip())#建立同义词key与字典key的关联。即将字典name加入同义词中\n",
    "            else:\n",
    "                logging.debug(\"name pos err-name:{},pos_tag:{}\".format(item['name'],pos_tag([item[\"name\"].lower()])))\n",
    "            # 如果有同义词，并且同义词是名字&&有主键名字，保留\n",
    "            if item['synonym_list']:\n",
    "                for synonym in item['synonym_list']:\n",
    "                    try:\n",
    "                        flag_synonym = pos_tag([synonym.lower()])[0][-1] in [\"NN\", \"NNS\", \"NNP\", \"NNPS\"] \\\n",
    "                        or (pos_tag([synonym.lower()])[0][-1] in [\"JJ\"] and (',' in synonym.lower() or '-' in synonym.lower()))\n",
    "\n",
    "                        if flag_synonym and flag_name:\n",
    "                            if (synonym in med_synonyms_name_dict) and (synonym == med_synonyms_name_dict[synonym]):  # 避免将已经存在的{\"name\":\"name\"}name实体覆盖掉\n",
    "                                continue\n",
    "                            else:\n",
    "                                med_synonyms_name_dict[synonym.lower().strip()] = copy.copy(item[\"name\"].lower().strip())\n",
    "\n",
    "                            ###\n",
    "                            if (item[\"name\"].lower()=='rna, small interfering'):\n",
    "                                print ('rna, small interfering',item['name'],pos_tag([item[\"name\"].lower()]))\n",
    "                            ###\n",
    "\n",
    "                        else :\n",
    "                            logging.debug(\"synonmy pos err-name:{},pos_tag:{}\".format(item['name'], pos_tag([item[\"name\"].lower()])))\n",
    "                    except:\n",
    "                        logging.debug(\"pos_tag synonym:{0},{1}\".format(synonym,item['synonym_list']))\n",
    "\n",
    "#    med_synonyms_name_dict_black = copy.copy(med_synonyms_name_dict)\n",
    "#    med_name_cate_dict_black = copy.copy(med_name_cate_dict)\n",
    "#    ############### 去除忽略的词-实体黑名单#############################\n",
    "#    with open('/Users/chihui/Documents/medical_entity_dict/black_dict_v2.0.txt') as f:\n",
    "#        for i in f.readlines():\n",
    "#            b_key=i.strip().lower()\n",
    "#            if b_key in med_name_cate_dict.keys():\n",
    "#                med_name_cate_dict.pop(b_key)\n",
    "#                logging.debug('cat_pop:{0}'.format(b_key))\n",
    "#            if b_key in med_synonyms_name_dict.keys():      #同义词中的key去除\n",
    "#                med_synonyms_name_dict.pop(b_key)\n",
    "#                logging.debug('syno_pop:{0}'.format(b_key))\n",
    "#\n",
    "#            for k,v in med_name_cate_dict_black.items():\n",
    "#                if len(k) <= 1:\n",
    "#                    try:\n",
    "#                        med_name_cate_dict.pop(k)\n",
    "#                    except:\n",
    "#                        logging.debug('med_name_cate_dict.pop(k):{}'.format(k))\n",
    "#                    logging.debug('med_name_cate_pop len<1:{0}'.format(k))\n",
    "#\n",
    "#            for k,v in med_synonyms_name_dict_black.items():\n",
    "#                if b_key == v or len(k) <= 1:    # 去除全部synonyms\n",
    "#                    if k in med_synonyms_name_dict:\n",
    "#                        med_synonyms_name_dict.pop(k)\n",
    "#                        logging.debug('synonyms_value_pop:{0}-{1}'.format(b_key,k))\n",
    "\n",
    "\n",
    "#    d_for = [med_synonyms_name_dict, med_name_cate_dict]\n",
    "\n",
    "#    return med_synonyms_name_dict, med_name_cate_dict\n",
    "    fl.write(json.dumps(med_name_cate_dict))\n",
    "    fl.close()\n",
    "    print (len(med_synonyms_name_dict),len(med_name_cate_dict))\n",
    "    return med_synonyms_name_dict, med_name_cate_dict\n",
    "    # 序列化\n",
    "    ##fs.write(pickle.dumps(d_for))\n",
    "\n",
    "    #fs.close()\n",
    "\n",
    "    #print (med_name_cate_dict)\n",
    "    \n",
    "    \n",
    "#   实体字典的单复数问题，统计字典中实体通过singularize()转换后单词发生变化的数量；字典中同时包含实体的单数和复数的数量；并统计其中category不相同的情况：\n",
    "def dict_singular_plural(syn_name_dict, name_cate_dict):\n",
    "    middle_synonyms_name_dict = copy.copy(syn_name_dict)\n",
    "    middle_name_cate_dict = copy.copy(name_cate_dict)\n",
    "    \n",
    "    singular_name_k_diff = 0\n",
    "    singular_plural_count = 0\n",
    "    singular_plural_cate_diff = 0\n",
    "    for k,v in middle_name_cate_dict.items():\n",
    "        if (k[-2:] in [\"ss\",\"ts\",\"es\",\"hs\",\"ds\",\"gs\",\"fs\",\"ks\",\"ls\",\"ms\",\"bs\",\"cs\",\"qs\",\"rs\",\"ys\",\"ps\"]) \\\n",
    "            or (k[-3:] in [\"ias\",\"ins\",\"ons\",\"ens\",\"ans\",\"eas\",\"men\"]) \\\n",
    "            or (k[-4:] in [\"feet\"]) \\\n",
    "            or (k[-5:] in [\"teeth\",\"women\"]) \\\n",
    "            or (k[-8:] in [\"children\"]):\n",
    "            singular_name = singularize(k)\n",
    "            if singular_name != k:\n",
    "                logging.debug('singular_name_k_diff:{0}#{1}'.format(singular_name, k))\n",
    "                singular_name_k_diff += 1\n",
    "            if (singular_name != k) and (singular_name in middle_name_cate_dict):\n",
    "                logging.debug('dict_singular_plural:{0}#{1}'.format(singular_name, k))\n",
    "                singular_plural_count += 1\n",
    "                if middle_name_cate_dict[singular_name] != v:\n",
    "                    logging.debug('singular_plural_cate_diff:singular_name#{0}#cate#{1}#plural_name#{2} \\\n",
    "                                  #cate#{3}'.format(singular_name, middle_name_cate_dict[singular_name], k, v))\n",
    "                    singular_plural_cate_diff += 1\n",
    "    print(str(singular_name_k_diff) + \"\\n\" + str(singular_plural_count) + \"\\n\" + str(singular_plural_cate_diff))\n",
    "\n",
    "\n",
    "#   对管哥给出的规则进行单复数转换，若单数在字典中存在，不做处理；若不存在，将单数增加到synonyms_name中\n",
    "def add_singular_to_synonyms(med_synonyms_name_dict, med_name_cate_dict):\n",
    "    add_synonyms_name_dict = copy.copy(med_synonyms_name_dict)\n",
    "    add_name_cate_dict = copy.copy(med_name_cate_dict)\n",
    "    \n",
    "    for name in add_name_cate_dict:\n",
    "        if (len(name) > 4) and (name[-5:] != \"trans\"):\n",
    "            if (name[-2:] in [\"ss\",\"ts\",\"es\",\"hs\",\"ds\",\"gs\",\"fs\",\"ks\",\"ls\",\"ms\",\"bs\",\"cs\",\"qs\",\"rs\",\"ys\",\"ps\"]) \\\n",
    "                or (name[-3:] in [\"ias\",\"ins\",\"ons\",\"ens\",\"ans\",\"eas\",\"men\"]) \\\n",
    "                or (name[-4:] in [\"feet\"]) \\\n",
    "                or (name[-5:] in [\"teeth\",\"women\"]) \\\n",
    "                or (name[-8:] in [\"children\"]):\n",
    "                singular_name = singularize(name)\n",
    "                if singular_name not in add_synonyms_name_dict:\n",
    "                    add_synonyms_name_dict[singular_name.strip()] = name\n",
    "                    logging.debug('add_singular_to_synonyms:{0}#{1}'.format(singular_name, name))\n",
    "    print(len(add_synonyms_name_dict),len(add_name_cate_dict))\n",
    "    return add_synonyms_name_dict, add_name_cate_dict\n",
    "\n",
    "\n",
    "def dict_label_concat(add_synonyms_name_dict, add_name_cate_dict):\n",
    "    '''\n",
    "    合并人工标注的实体，纠正、增加\n",
    "    遍历人工标注文件，查询sym——name字典，返回name。修改name_cate字典中的category；如果不存在就增加入name_cate,sym-name。\n",
    "    注意处理大写变小写，单复数问题；（注：其中结尾为\"ta\"、\"ia\"的不用进行单复数处理）\n",
    "    ****** 单复数处理新规则：按早期研发给的规则进行单复数转换******\n",
    "    category为uncertain的（暂时不做处理）\n",
    "    '''\n",
    "    synonyms_name_dict = copy.copy(add_synonyms_name_dict)\n",
    "    name_category_dict = copy.copy(add_name_cate_dict)\n",
    "    fl = open('/Users/ch/Documents/medical_entity_dict/modify_entity_dict/name_category_dict.json','w')\n",
    "    with open('/Users/ch/Documents/medical_entity_dict/modify_entity_dict/correct_add_sent_cate_v1.0') as file:\n",
    "        \n",
    "        file.seek(0,0)\n",
    "        for line in file:\n",
    "            sent_word = line.split(\"\\t\")[0].lower().strip()\n",
    "#            if sent_word[-2:] != \"ta\":\n",
    "#                sent_word = singularize(sent_word)\n",
    "                \n",
    "            category = line.split(\"\\t\")[1].replace(\"\\n\",\"\").strip()\n",
    "            cate_list = [\"drugs\",\"gene\",\"protein\",\"compound\",\"disease\",\"symptom\",\"organism\",\"anatomy\",\"equipment\",\"phenomenon\"]\n",
    "            if category not in cate_list:\n",
    "                print(sent_word)\n",
    "                \n",
    "            if len(sent_word) > 2:\n",
    "                if sent_word in synonyms_name_dict:\n",
    "                    name = synonyms_name_dict[sent_word]\n",
    "                    name_category_dict[name] = category\n",
    "                    logging.debug('name_cate_modify:{0}#{1}'.format(name, category))\n",
    "                else:\n",
    "                    name = sent_word\n",
    "                    name_category_dict[name] = category\n",
    "                    synonyms_name_dict[name] = name\n",
    "                    logging.debug('name_cate_add:{0}#{1}'.format(name, category))\n",
    "                if sent_word in name_category_dict:\n",
    "                    name_category_dict[sent_word] = category\n",
    "                    logging.debug('name_cate_modify:{0}#{1}'.format(sent_word, category))\n",
    "                    \n",
    "    fl.write(json.dumps(name_category_dict))\n",
    "    fl.close()\n",
    "    print(len(synonyms_name_dict),len(name_category_dict))\n",
    "    return synonyms_name_dict, name_category_dict\n",
    "\n",
    "\n",
    "def dict_label_relation_concat(synonyms_name_dict, name_category_dict):\n",
    "    '''\n",
    "    将21个有向关系中的所有实体加入字典中，e1、e2 + category\n",
    "    如果字典中已经存在e1、e2，以字典为准不做修改；如果字典中不存在，就把实体加入到字典的name_cate,sym-name中。\n",
    "    '''\n",
    "    syn_name_dict = copy.copy(synonyms_name_dict)\n",
    "    name_cate_dict = copy.copy(name_category_dict)\n",
    "    \n",
    "    fl = open('/Users/ch/Documents/medical_entity_dict/modify_entity_dict/name_cate_dict.json','w')\n",
    "    file_folder_path = r\"/Users/ch/Documents/entity_relation_dict/quchong_relation_dict/\"\n",
    "    file_path_list = []\n",
    "    for file_path_root,_,file_name_list in os.walk(file_folder_path):\n",
    "        for file_name in file_name_list:\n",
    "            if \".dict\" in file_name:\n",
    "                file_path_list.append(os.path.join(file_path_root,file_name))\n",
    "#    file_name_list = ['compound_protein_treat.dict','disease_disease_coexist.dict','drugs_protein_target.dict',\n",
    "#                      'drugs_disease_treat.dict','gene_disease_cause.dict','gene_protein_express.dict',\n",
    "#                      'drugs_disease_treat.dict 2','drugs_gene_target.dict','drugs_protein_target.dict 2','gene_disease_cause.dict 2',\n",
    "#                      'gene_gene_interact.dict','protein_disease_cause.dict','protein_organism_belong.dict']\n",
    "    num = 0\n",
    "    for file_name in file_path_list:\n",
    "        num = num + 1\n",
    "        print(num)\n",
    "#        with open('/Users/ch/Documents/medical_entity_dict/relationship_dict_all/' + file_name) as file:\n",
    "        with open(file_name,'r') as file:\n",
    "            file.seek(0,0)\n",
    "            line = file.readline()\n",
    "            while(line):            \n",
    "                line_dict = json.loads(line)\n",
    "                flag_source = 0\n",
    "                sources = line_dict[\"sources\"]  #  目前第三批更新的关系中的新实体不加入实体字典中，判断是否来源均为第三批关系字典\n",
    "                if (\"-1\" in sources) or (\"-2\" in sources) or (\"-3\" in sources) or (\"-4\" in sources) or (\"-5\" in sources) or \\\n",
    "                    (\"-6\" in sources) or (\"-7\" in sources) or (\"-8\" in sources) or (\"-9\" in sources):  # (\"-1\"--\"-9\"为前两批的关系字典)\n",
    "                    flag_source = 1\n",
    "                if flag_source == 1:\n",
    "                    e1 = line_dict[\"e1\"].lower().strip()\n",
    "                    e1_category = os.path.basename(file_name).split(\"_\")[0]  #实体e1的category\n",
    "                    if e1:\n",
    "                        entity1 = pos_tag([e1])[0][-1] in [\"NN\", \"NNS\", \"NNP\", \"NNPS\"]\\\n",
    "                            or (pos_tag([e1])[0][-1] in [\"JJ\"] and (',' in e1 or '-' in e1))   #化合物是形容词，保留了特殊符号的\n",
    "                        if entity1 and len(e1) > 3:\n",
    "                            if e1 not in syn_name_dict:\n",
    "                                name_cate_dict[e1] = e1_category\n",
    "                                syn_name_dict[e1] = e1\n",
    "                                logging.debug('name_cate_relation_add:{0}#{1}'.format(e1, e1_category))\n",
    "                        else:\n",
    "                            logging.debug('relation_dict_entity_length(0_3)pop:{0}'.format(e1, e1_category))  # 将关系字典中实体长度小于等于3的实体筛掉\n",
    "    #                    if e1 == \"to\" or e1 == \"be\":\n",
    "    #                        print(e1, e1_category)\n",
    "    \n",
    "                    e2 = line_dict[\"e2\"].lower().strip()\n",
    "                    e2_category = os.path.basename(file_name).split(\"_\")[1]  #实体e2的category\n",
    "                    if e2:\n",
    "                        entity2 = pos_tag([e2])[0][-1] in [\"NN\", \"NNS\", \"NNP\", \"NNPS\"]\\\n",
    "                            or (pos_tag([e2])[0][-1] in [\"JJ\"] and (',' in e2 or '-' in e2))   #化合物是形容词，保留了特殊符号的\n",
    "                        if entity2 and len(e2) > 3:\n",
    "                            if e2 not in syn_name_dict:\n",
    "                                name_cate_dict[e2] = e2_category\n",
    "                                syn_name_dict[e2] = e2\n",
    "                                logging.debug('name_cate_relation_add:{0}#{1}'.format(e2, e2_category))\n",
    "                        else:\n",
    "                            logging.debug('relation_dict_entity_length(0_3)pop:{0}'.format(e2, e2_category))  # 将关系字典中实体长度小于等于3的实体筛掉\n",
    "    #                    if e2 == \"to\" or e2 == \"be\":\n",
    "    #                        print(e2, e2_category)\n",
    "                    \n",
    "    #                if e2[-2:] != \"ta\":\n",
    "    #                    e2 = singularize(e2)\n",
    "                line = file.readline()\n",
    "\n",
    "    print(len(syn_name_dict),len(name_cate_dict))\n",
    "    fl.write(json.dumps(name_cate_dict))\n",
    "    fl.close()\n",
    "    return syn_name_dict, name_cate_dict\n",
    "    ############### 去除忽略的词-实体黑名单#############################    \n",
    "def del_black_dict(syn_name_dict, name_cate_dict):\n",
    "#   删除黑名单中的实体\n",
    "    med_synonyms_name_dict_black = copy.copy(syn_name_dict)\n",
    "    med_name_cate_dict_black = copy.copy(name_cate_dict)\n",
    "    fl = open('/Users/ch/Documents/medical_entity_dict/modify_entity_dict/name_cate_dict_final.json','w')\n",
    "    fs = open('/Users/ch/Documents/medical_entity_dict/modify_entity_dict/medical_entity_dict_v4.3.pkl','wb')\n",
    "    fs_json = open('/Users/ch/Documents/medical_entity_dict/modify_entity_dict/medical_entity_dict_v4.3.json','w')\n",
    "    with open('/Users/ch/Documents/medical_entity_dict/black_dict_v3.0.txt') as f:        \n",
    "        for i in f.readlines():\n",
    "            b_key = i.strip().lower()   #做大写变小写处理\n",
    "            if b_key in name_cate_dict.keys():\n",
    "                name_cate_dict.pop(b_key)\n",
    "                logging.debug('cat_pop:{0}'.format(b_key))\n",
    "            if b_key in syn_name_dict.keys():      #同义词中的key去除\n",
    "                syn_name_dict.pop(b_key)\n",
    "                logging.debug('syno_pop:{0}'.format(b_key))\n",
    "\n",
    "            for k,v in med_synonyms_name_dict_black.items():\n",
    "                if b_key == v or len(k) <= 2:    # 如果name在黑名单里，或者长度小于等于1，去除name对应的全部synonyms,\n",
    "#                if b_key == v or len(k) <= 2 or len(v) <= 2:\n",
    "                    if k in syn_name_dict:\n",
    "                        syn_name_dict.pop(k)\n",
    "                        logging.debug('synonyms_value_pop:{0}#{1}'.format(b_key,k))\n",
    "#    如果 synonyms长度大于2，name长度小于等于2，那么就保留 synonyms 删除 name。                        \n",
    "#                elif len(k) > 2 and len(v) <= 2:    \n",
    "#                    syn_name_dict[k] = k\n",
    "#                    name_cate_dict[k] = name_cate_dict[v]\n",
    "#                    logging.debug('synonyms_retain_name_pop:{0}#{1}'.format(k,v))\n",
    "                    \n",
    "        for k,v in med_synonyms_name_dict_black.items():\n",
    "            if len(k) > 2 and len(v) <= 2:\n",
    "                if k in syn_name_dict:\n",
    "                    syn_name_dict[k] = k\n",
    "                    name_cate_dict[k] = name_cate_dict[v]\n",
    "                    logging.debug('synonyms_retain_name_pop:{0}#{1}'.format(k,v))\n",
    "                    \n",
    "        for k,v in med_name_cate_dict_black.items():\n",
    "            if len(k) <= 2:\n",
    "                try:\n",
    "                    name_cate_dict.pop(k)\n",
    "                except:\n",
    "                    logging.debug('name_cate_dict.pop(k):{0}'.format(k))\n",
    "                logging.debug('name_cate_pop len<=2:{0}'.format(k))\n",
    "#    将 adora2a 的同义词 adenosine a2a receptor、adenosine receptor a2a 归一到 adora2a 上。\n",
    "        syn_name_dict[\"adenosine a2a receptor\"] = \"adora2a\"\n",
    "        syn_name_dict[\"adenosine receptor a2a\"] = \"adora2a\"\n",
    "#        name_cate_dict.pop(\"adenosine a2a receptor\")\n",
    "#        name_cate_dict.pop(\"adenosine receptor a2a\")\n",
    "        print(len(syn_name_dict),len(name_cate_dict))\n",
    "    fl.write(json.dumps(name_cate_dict))\n",
    "    for k,v in name_cate_dict.items():\n",
    "        if (k=='isoleucine'):\n",
    "            print ('debug::::::::',k,v)\n",
    "    fl.close()\n",
    "    # 序列化\n",
    "    dict_concat = [syn_name_dict, name_cate_dict]\n",
    "    pickle.dump(dict_concat, fs)\n",
    "    json.dump(dict_concat,fs_json,indent=4)\n",
    "    \n",
    "    fs.close()\n",
    "    return(syn_name_dict, name_cate_dict)\n",
    "\n",
    "\n",
    "#    print (med_name_cate_dict)\n",
    "\n",
    "\n",
    "log_conf()\n",
    "\n",
    "med_synonyms_name_dict, med_name_cate_dict = gen_dict()\n",
    "\n",
    "add_synonyms_name_dict, add_name_cate_dict = add_singular_to_synonyms(med_synonyms_name_dict, med_name_cate_dict)\n",
    "synonyms_name_dict, name_category_dict = dict_label_concat(add_synonyms_name_dict, add_name_cate_dict)\n",
    "syn_name_dict, name_cate_dict = dict_label_relation_concat(synonyms_name_dict, name_category_dict)\n",
    "syn_name_dict, name_cate_dict = del_black_dict(syn_name_dict, name_cate_dict)\n",
    "\n",
    "\n",
    "#dict_singular_plural(med_synonyms_name_dict, med_name_cate_dict)\n",
    "#loads_pickle('/Users/ch/Documents/medical_entity_dict/relationship_dict/dict.pkl')\n",
    "#dict_singular_plural(syn_name_dict, name_cate_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "bad magic number in 'pattern': b'\\x03\\xf3\\r\\n'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7e8790a2a2fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: bad magic number in 'pattern': b'\\x03\\xf3\\r\\n'"
     ]
    }
   ],
   "source": [
    "import pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pattern.en'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-104d6f1e78f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0men\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pattern.en'"
     ]
    }
   ],
   "source": [
    "import pattern.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/chihui/anaconda3/bin/python\n"
     ]
    }
   ],
   "source": [
    "print (sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pattern.en'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ddc392fc74e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mMODULE\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODULE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0men\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparsetree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pattern.en'"
     ]
    }
   ],
   "source": [
    "MODULE = '/mnt/chihui/anaconda3/lib/python3.7/site-packages/pattern'\n",
    "import sys\n",
    "if MODULE not in sys.path: sys.path.append(MODULE)\n",
    "from pattern.en import parsetree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/chihui/anaconda3/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

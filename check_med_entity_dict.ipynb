{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "421557 228901\n"
     ]
    }
   ],
   "source": [
    "#import _pickle as pickle\n",
    "import pickle\n",
    "import json\n",
    "with open('./medical_entity_dict_v5.0.pkl','rb') as file:\n",
    "    med_synonyms_name_dict, med_name_cate_dict = pickle.loads(file.read())\n",
    "    print(len(med_synonyms_name_dict),len(med_name_cate_dict))\n",
    "    \n",
    "#with open('./medical_entity_Name_Catetgory_v5.0.json','w') as fl:\n",
    "#    fl.write(json.dumps(med_name_cate_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "421078 228428\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import json\n",
    "with open('./medical_entity_dict_v4.4.pkl','rb') as file:\n",
    "    synonyms_name_dict, name_cate_dict = pickle.loads(file.read())\n",
    "    print(len(synonyms_name_dict),len(name_cate_dict))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caspase-8\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "name = \"caspase-8\".lower()\n",
    "if name in med_synonyms_name_dict:\n",
    "    print(med_synonyms_name_dict[name])\n",
    "else:\n",
    "    print(\"name not in dict\")\n",
    "#for k,v in med_synonyms_name_dict.items():\n",
    "#    if v == \"tissue-type plasminogen activator\":\n",
    "#        print(k + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gene\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "name = \"caspase-8\".lower()\n",
    "if name in med_name_cate_dict:\n",
    "    print(med_name_cate_dict[name])\n",
    "else:\n",
    "    print(\"name not in dict\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caspase-8\n",
      "apoptotic protease mch-5\n",
      "apoptotic cysteine protease\n",
      "fadd-homologous ice/ced-3-like protease\n",
      "fadd-like ice\n",
      "ice-like apoptotic protease 5\n",
      "caspase-8 subunit p10\n",
      "cap4\n",
      "caspase-8 subunit p18\n",
      "mort1-associated ced-3 homolog\n"
     ]
    }
   ],
   "source": [
    "for k, v in med_synonyms_name_dict.items():\n",
    "#    if v == \"vitamin\":\n",
    "#        print(k)\n",
    "    if v == \"caspase-8\":\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "pattern = re.compile(r\"\\d+\\.\\-?\\d{0,10}\\.\\-?\\d{0,10}\\.\\-?\\d{0,10}\")\n",
    "name = \"hijhiuohoh\"\n",
    "dig_result = pattern.findall(name)\n",
    "print(dig_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./medical_entity_Name_Category_v4.4.json','w') as fl:\n",
    "    fl.write(json.dumps(name_cate_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('./medical_entity_dict_v4.3_synonyms_name_dict.txt','a') as file:\n",
    "    for k, v in med_synonyms_name_dict.items():\n",
    "        file.write(k + \"\\t\" + v + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('./medical_entity_dict_v4.3_name_cate_dict.txt','a') as file:\n",
    "    for k, v in med_name_cate_dict.items():\n",
    "        file.write(k + \"\\t\" + v + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syn_entity_name_same:856;syn_entity_name_diff:2532;exist_syn_entity:3388;not_exist_syn_entity:150323\n"
     ]
    }
   ],
   "source": [
    "#  统计实体字典中含有“-”的实体，例如：tcf-15、tcf 15 是否需要合并归一\n",
    "import json\n",
    "import re\n",
    "\n",
    "syn_entity_name_diff = 0\n",
    "syn_entity_name_same = 0\n",
    "exist_syn_entity = 0\n",
    "not_exist_syn_entity = 0\n",
    "with open('./contain_entity_normalization.txt','a') as file:\n",
    "    for k, v in med_synonyms_name_dict.items():\n",
    "#        if (\"-\" in k) or (\"_\" in k):   #  存在\"_\"的实体只有4个有同义词 \n",
    "#        pattern = re.compile(r\"[a-z]+-\\d+\")\n",
    "        if (\"-\" in k):\n",
    "            k_cate = med_name_cate_dict[v]\n",
    "            syn_entity = k.replace(\"-\",\"\").replace(\"_\",\"\")\n",
    "            if syn_entity in med_synonyms_name_dict:\n",
    "                exist_syn_entity += 1\n",
    "                syn_entity_name = med_synonyms_name_dict[syn_entity]\n",
    "                syn_entity_cate = med_name_cate_dict[syn_entity_name]\n",
    "                if v != syn_entity_name:\n",
    "                    syn_entity_name_diff += 1\n",
    "                    file.write(k + \"\\t\" + v + \"\\t\" + k_cate + \"\\t\" + syn_entity + \"\\t\" + syn_entity_name + \"\\t\" + syn_entity_cate + \"\\n\")\n",
    "#                    file.write(json.dumps({k:k_cate,syn_entity:syn_entity_cate}) + \"\\n\")\n",
    "                else:\n",
    "                    syn_entity_name_same += 1\n",
    "            else:\n",
    "                not_exist_syn_entity += 1\n",
    "#                file.write(json.dumps({k:k_cate}) + \"\\n\")\n",
    "print(\"syn_entity_name_same:\" + str(syn_entity_name_same) +\";\"+ \"syn_entity_name_diff:\" + str(syn_entity_name_diff) +\";\"+ \"exist_syn_entity:\" + str(exist_syn_entity) +\";\"+ \"not_exist_syn_entity:\" + str(not_exist_syn_entity))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hbv::hbv::protein\n",
      "merr::merr::protein\n",
      "lamb::lamb::protein\n",
      "lamb preparation::lamb::protein\n",
      "shark::shark::protein\n",
      "lentil::lentil::protein\n",
      "lentil seed extract::lentil::protein\n",
      "radish::radish::protein\n",
      "mugwort::mugwort::protein\n",
      "scallop::scallop::protein\n",
      "lettuce::lettuce::protein\n",
      "hookworm::hookworm::protein\n",
      "mackerel::mackerel::protein\n",
      "amaranth::amaranth::protein\n",
      "acacia::acacia::protein\n",
      "babesia::babesia::protein\n",
      "dogs::dogs::protein\n",
      "leech::leech::protein\n",
      "scorpion::scorpion::protein\n",
      "amoeba::amoeba::protein\n",
      "candida::candida::protein\n",
      "colicins::colicins::protein\n",
      "colicins e::colicins::protein\n",
      "colicin e2::colicins::protein\n",
      "colicin e8::colicins::protein\n",
      "colicin v::colicins::protein\n",
      "precolicin e1::colicins::protein\n",
      "colicin ib::colicins::protein\n",
      "colicin n::colicins::protein\n",
      "colicin k::colicins::protein\n",
      "colicin hsc10::colicins::protein\n",
      "colicin ia::colicins::protein\n",
      "colicin m::colicins::protein\n",
      "colicins e9::colicins::protein\n",
      "colicin e3::colicins::protein\n",
      "colicin b::colicins::protein\n",
      "colicin e1::colicins::protein\n",
      "colicin k-k235::colicins::protein\n",
      "colicin a::colicins::protein\n",
      "colicin::colicins::protein\n",
      "ginkgo::ginkgo::protein\n",
      "hoga::oat::protein\n",
      "oat::oat::protein\n",
      "mog::mog::protein\n",
      "btn6::mog::protein\n",
      "btnl11::mog::protein\n",
      "leek::leek::protein\n",
      "parva::parva::protein\n",
      "flj12254::parva::protein\n",
      "matrix-remodelling associated 2::parva::protein\n",
      "flj10793::parva::protein\n",
      "carrot::carrot::protein\n",
      "oyster::oyster::protein\n",
      "oyster allergenic extract::oyster::protein\n",
      "eastern oyster::oyster::protein\n",
      "lobster::lobster::protein\n",
      "lobster allergenic extract::lobster::protein\n",
      "american lobster::lobster::protein\n",
      "plantain::plantain::protein\n",
      "muscimol::muscimol::protein\n",
      "prion::prion::protein\n",
      "beet::beet::protein\n",
      "sugar beet allergenic extract::beet::protein\n",
      "flounder::flounder::protein\n",
      "southern flounder::flounder::protein\n",
      "flounder allergenic extract::flounder::protein\n",
      "listeria::listeria::protein\n",
      "onion::onion::protein\n",
      "pumpkin::pumpkin::protein\n",
      "allergenic extract- pumpkin cucurbita pepo::pumpkin::protein\n",
      "turkey::turkey::protein\n",
      "horseradish peroxidase::horseradish peroxidase::protein\n",
      "ferrihorseradish peroxidase::horseradish peroxidase::protein\n",
      "horseradish peroxidase ii::horseradish peroxidase::protein\n",
      "horseradish peroxidase iii::horseradish peroxidase::protein\n",
      "alpha-peroxidase::horseradish peroxidase::protein\n"
     ]
    }
   ],
   "source": [
    "#  只纠正实体字典的 name_cate  \n",
    "import json\n",
    "\n",
    "with open('./only_correct_name_cate.txt','r') as file, open('./medical_entity_dict_v4.6.pkl','rb') as fl:\n",
    "    med_synonyms_name_dict, med_name_cate_dict = pickle.loads(fl.read())\n",
    "    \n",
    "    entity_list = []\n",
    "    file.seek(0,0)\n",
    "    for line in file:\n",
    "        entity = line.strip().split(\"\\t\")[0]\n",
    "        correct_category = line.strip().split(\"\\t\")[1]\n",
    "        if entity in med_synonyms_name_dict:\n",
    "            name = med_synonyms_name_dict[entity]\n",
    "            entitydict_cate = med_name_cate_dict[name]\n",
    "            if correct_category != entitydict_cate:\n",
    "                entity_list.append(entity)\n",
    "        \n",
    "    for word in entity_list:\n",
    "        for k,v in med_synonyms_name_dict.items():\n",
    "            if (k == word) or (v == word):\n",
    "                print(k + \"::\" + v)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "467628 264373\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import json\n",
    "with open('./drugs_disease_dict_v1.0.pkl','rb') as file:\n",
    "    drugs_disease_synonyms_name_dict, drugs_disease_name_cate_dict = pickle.loads(file.read())\n",
    "    print(len(drugs_disease_synonyms_name_dict),len(drugs_disease_name_cate_dict))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('./drugs_disease_synonyms_name_dict_test.txt','a') as file:\n",
    "#    drugs_disease_synonyms_name_dict = json.loads(file.readline())\n",
    "    \n",
    "    for k, v in drugs_disease_synonyms_name_dict.items():\n",
    "        file.write(k + \"\\t\" + v + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('./drugs_disease_name_cate_dict_test.txt','a') as fl:\n",
    "    for k, v in drugs_disease_name_cate_dict.items():\n",
    "        fl.write(k + \"\\t\" + json.dumps(v) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name not in dict\n"
     ]
    }
   ],
   "source": [
    "if \"re\" in drugs_disease_synonyms_name_dict:\n",
    "    print(drugs_disease_synonyms_name_dict[\"re\"])\n",
    "else:\n",
    "    print(\"name not in dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'category': 'disease', 'classification_1': '', 'classification_2': '', 'classification_3': ''}\n"
     ]
    }
   ],
   "source": [
    "if \"新生物\" in drugs_disease_name_cate_dict:\n",
    "    print(drugs_disease_name_cate_dict[\"新生物\"])\n",
    "else:\n",
    "    print(\"name not in dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "fl2 = open('./med_name_cate_dict.json','w')\n",
    "for k,v in med_name_cate_dict.items():\n",
    "    fl2.write(k + \"\\t\" + v + \"\\n\")\n",
    "fl2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5960\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# 查看关系字典中存在，实体字典中不存在的实体，是否加入到了实体字典中。\n",
    "entity_not_in_dict_list = []\n",
    "entity_not_in_dict_count = 0\n",
    "with open('./unexist_entity.json','r') as file:\n",
    "    file.seek(0,0)\n",
    "    list_ = json.load(file)\n",
    "    for entity_list in list_:\n",
    "        entity = entity_list[0]\n",
    "        if entity not in med_synonyms_name_dict:\n",
    "            entity_not_in_dict_list.append(entity)\n",
    "            entity_not_in_dict_count += 1\n",
    "            \n",
    "print(entity_not_in_dict_count)\n",
    "#print(med_name_cate_dict[\"(4r)-limonene\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from nltk import pos_tag\n",
    "\n",
    "e1 = \"il-1rii\"\n",
    "entity1 = pos_tag([e1])[0][-1] in [\"NN\", \"NNS\", \"NNP\", \"NNPS\"]\\\n",
    "                        or (pos_tag([e1])[0][-1] in [\"JJ\"] and (',' in e1 or '-' in e1))\n",
    "print(entity1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disease:103883\n",
      "organism:6896\n",
      "symptom:3729\n",
      "anatomy:3824\n",
      "phenomenon:2984\n",
      "drugs:44230\n",
      "equipment:5267\n",
      "protein:64073\n",
      "gene:103268\n",
      "compound:86906\n"
     ]
    }
   ],
   "source": [
    "#  统计加上同义词的实体总量，以及各个类别的实体数量\n",
    "entity_cate_count = {}\n",
    "\n",
    "for synonym, name in med_synonyms_name_dict.items():\n",
    "    category = med_name_cate_dict[name]\n",
    "    if category not in entity_cate_count:\n",
    "        entity_cate_count[category] = 1\n",
    "    else:\n",
    "        entity_cate_count[category] += 1\n",
    "for key, value in entity_cate_count.items():\n",
    "    print(key + \":\" + str(value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "res = {}\n",
    "with open('./medical_entity_dict_v2.0.txt','r') as file, open('./不在syn_name中-在name_cate中的实体.txt','w') as fl:\n",
    "    file.seek(0,0)\n",
    "    \n",
    "    for line in file:\n",
    "        line_dict = json.loads(line.strip())\n",
    "        name = line_dict[\"name\"]\n",
    "        if name in entity_list:\n",
    "            if name not in res:\n",
    "                res[name] = [line_dict]\n",
    "            else:\n",
    "                res[name].append(line_dict)\n",
    "                \n",
    "        synonym_list = line_dict[\"synonym_list\"]\n",
    "        for synonym in synonym_list:\n",
    "            if synonym in entity_list:\n",
    "                if synonym not in res:\n",
    "                    res[synonym] = [line_dict]\n",
    "                else:\n",
    "                    res[synonym].append(line_dict)\n",
    "    for k,v in res.items():\n",
    "        fl.write(k + \"####\" + str(v) + \"\\n\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "num = 0\n",
    "del_entity_list = []\n",
    "for key,value in res.items():\n",
    "    for v in value:\n",
    "        if v[\"name\"] not in del_entity_list:\n",
    "            del_entity_list.append(v[\"name\"])\n",
    "        else:\n",
    "            num += 1\n",
    "            #print(v[\"name\"])\n",
    "print(num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "if \"paranasal sinus cancer\" in del_entity_list:\n",
    "    print(\"yes\")\n",
    "else:\n",
    "    print(\"no\")\n",
    "    \n",
    "#print(del_entity_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "#    将name_cate_dict 中存在，synonyms_name_dict 中不存在的248组实体，从实体黑名单中删除。\n",
    "with open('./black_dict_v2.0.txt','r') as file, open('./black_dict_v3.0.txt','w') as fl:\n",
    "    file.seek(0,0)\n",
    "    for line in file:\n",
    "        if line.strip() in del_entity_list:\n",
    "            continue\n",
    "        else:\n",
    "            fl.write(line.strip() + '\\n')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "del_entity_library_list = []\n",
    "with open('./black_list_entity_library','r') as file:\n",
    "    file.seek(0,0)\n",
    "    for line in file:\n",
    "        entity = line.strip()\n",
    "        if entity not in del_entity_library_list:\n",
    "            del_entity_library_list.append(entity)\n",
    "#    按照丽君反馈的规则将一部分实体从实体库中删除\n",
    "with open('./medical_entity_dict_v2.0.txt','r') as fo, open('./medical_entity_dict_v3.0.txt','w') as fw:\n",
    "    fo.seek(0,0)\n",
    "    for line_ in fo:\n",
    "        line_dict = json.loads(line_.strip())\n",
    "        name = line_dict[\"name\"]\n",
    "        if name in del_entity_library_list:\n",
    "            continue\n",
    "        else:\n",
    "            fw.write(json.dumps(line_dict) + '\\n')\n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'disease', 'symptom'}, {'disease'}, {'disease', 'anatomy'}, {'disease', 'organism'}, {'protein', 'drugs'}, {'compound', 'drugs'}, {'organism', 'drugs'}, {'disease', 'gene'}, {'protein', 'gene'}, {'compound'}, {'protein', 'compound'}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "#    不用以下规则处理，直接将 248 个实体从实体库中删除。\n",
    "cate_list_count = []\n",
    "black_list = []\n",
    "for key,value_list in res.items():\n",
    "    cate_list = []\n",
    "    source_list = []\n",
    "    for value in value_list:\n",
    "        cate = value[\"category\"]\n",
    "        cate_list.append(cate)\n",
    "        source = value[\"source\"]\n",
    "        source_list.append(source)\n",
    "        \n",
    "    diff_cate_list = set(cate_list)\n",
    "    if diff_cate_list not in cate_list_count:\n",
    "        cate_list_count.append(diff_cate_list)\n",
    "        \n",
    "    if (len(cate_list) == 2) and (\"gene\" in cate_list) and (\"protein\" in cate_list):\n",
    "        for value in value_list:\n",
    "#    如果 category: gene、protein,那么就取cate为gene的数据，将cate为protein的数据加入到黑名单列表中\n",
    "            if value[\"category\"] == \"protein\":\n",
    "                black_name = value[\"name\"]\n",
    "                black_list.append(black_name)\n",
    "    if (len(cate_list) == 2) and (\"disease\" in cate_list) and (\"symptom\" in cate_list):\n",
    "        for value in value_list:\n",
    "#    如果 category: symptom、disease,那么就取cate为symptom的数据，将cate为disease的数据加入到黑名单列表中\n",
    "            if value[\"category\"] == \"disease\":\n",
    "                black_name = value[\"name\"]\n",
    "                black_list.append(black_name)\n",
    "    if (len(diff_cate_list) == 1) and (\"disease\" in diff_cate_list) and (\"icd11\" in source_list):\n",
    "        for value in value_list:\n",
    "#    如果 category: disease、disease，取来源为icd_11 的数据\n",
    "            if value[\"source\"] != \"icd11\":\n",
    "                black_name = value[\"name\"]\n",
    "                black_list.append(black_name)\n",
    "    if (len(diff_cate_list) == 2) and (\"protein\" in cate_list) and (\"gene\" not in cate_list):      \n",
    "        for value in value_list:\n",
    "#    如果 category: protein与其他类别，取 protein\n",
    "            if value[\"category\"] != \"protein\":\n",
    "                black_name = value[\"name\"]\n",
    "                black_list.append(black_name)\n",
    "    \n",
    "print(cate_list_count)      \n",
    "    \n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['disease', 'disease']\n",
      "{'disease'}\n"
     ]
    }
   ],
   "source": [
    "cate_list1 = [\"disease\",\"disease\"]\n",
    "cate_list2 = set(cate_list1)\n",
    "print(cate_list1)\n",
    "print(cate_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'house dust'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-4d493ed10390>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"house dust\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'house dust'"
     ]
    }
   ],
   "source": [
    "res.pop(\"house dust\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "def countNum(string):\n",
    "    '''\n",
    "    :param string:\n",
    "    :return:\n",
    "    '''\n",
    "    dic = {}\n",
    "    result = [0, 0]\n",
    "    if len(string) > 0:\n",
    "        l = len(string)\n",
    "    else:\n",
    "        l = 1\n",
    "    for char in string:\n",
    "        if char >= '\\u4e00' and char <= '\\u9fa5': # 判断是否是汉字\n",
    "            result[0] += 1\n",
    "        else:\n",
    "            result[1] += 1\n",
    "\n",
    "    dic['zh'] = result[0]\n",
    "    dic['no_zh'] = result[1]\n",
    "    return  dic['zh'] / l\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    word = \"你好啊hao\"\n",
    "    rate = countNum(word)\n",
    "    print(rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-18-37c700dc0104>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-18-37c700dc0104>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    a = \"3',4'-Methylenedioxy-3- methoxy-2''-\u001b[0m\n\u001b[0m                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "a = \"3',4'-Methylenedioxy-3- methoxy-2''-\n",
    "    (2-hydroxypropan-2-yl)-\n",
    "    furano-(2'',3'':7,8)-flavone\"\n",
    "\n",
    "print(a)\n",
    "\n",
    "b = a.replace(\"\\n\",\"\")\n",
    "print(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  disease_disease 关系库\n",
    "\n",
    "import json\n",
    "\n",
    "with open('/home/chihui/chihui/jupyter/data/relationship_dict/all_relation_dict_file_v2.0/relation_dict_in_entity_dict/disease_disease_coexist.dict','r') as file, \\\n",
    "    open('./disease_disease_del_data.txt','r') as fl, \\\n",
    "    open('./relation_dict_in_entity_dict_after_correct/disease_disease_coexist.dict','w') as fw:\n",
    "    \n",
    "    del_relation_list = []\n",
    "    fl.seek(0,0)\n",
    "    for line in fl:\n",
    "        del_relation = line.strip()\n",
    "        del_relation_list.append(del_relation)\n",
    "        \n",
    "    file.seek(0,0)\n",
    "    for line in file:\n",
    "        line_dict = json.loads(line.strip())\n",
    "        source_list = line_dict[\"sources\"]\n",
    "        e1 = line_dict[\"e1\"]\n",
    "        e2 = line_dict[\"e2\"]\n",
    "        if e1 == e2:\n",
    "            continue\n",
    "        else:\n",
    "            if (\"-1\" in source_list) or (\"-10\" in source_list):      #  来源库为 ctd、ttd\n",
    "                continue\n",
    "            elif (\"-9\" in source_list):   #  来源库为 malacards\n",
    "                score_list = line_dict[\"scores\"]\n",
    "                for score in score_list:\n",
    "                    if float(score) >= 11:\n",
    "                        fw.write(json.dumps(line_dict) + \"\\n\")\n",
    "            elif (\"-11\" in source_list):\n",
    "                e1_e2_combine = e1 + \"####\" + e2\n",
    "                if e1_e2_combine in del_relation_list:\n",
    "                    continue\n",
    "                else:\n",
    "                    fw.write(json.dumps(line_dict) + \"\\n\")\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  equipment_disease 关系库\n",
    "\n",
    "import json\n",
    "\n",
    "with open('/home/chihui/chihui/jupyter/data/relationship_dict/all_relation_dict_file_v2.0/relation_dict_in_entity_dict/equipment_disease_diagnose|treat.dict','r') as file, \\\n",
    "    open('./equipment_disease_del_data.txt','r') as fl, \\\n",
    "    open('./relation_dict_in_entity_dict_after_correct/equipment_disease_diagnose|treat.dict','w') as fw1, \\\n",
    "    open('./relation_dict_in_entity_dict_after_correct/drugs_disease_treat.dict','w') as fw2:\n",
    "    \n",
    "    del_relation_list = []\n",
    "    fl.seek(0,0)\n",
    "    for line in fl:\n",
    "        del_relation = line.strip()\n",
    "        del_relation_list.append(del_relation)\n",
    "    \n",
    "    file.seek(0,0)\n",
    "    for line in file:\n",
    "        line_dict = json.loads(line.strip())\n",
    "        e1 = line_dict[\"e1\"]\n",
    "        e2 = line_dict[\"e2\"]\n",
    "        e1_e2_combine = e1 + \"####\" + e2\n",
    "        \n",
    "        if e1 == \"trypan blue\":\n",
    "            fw1.write(json.dumps(line_dict) + \"\\n\")\n",
    "        elif (e1 == \"tacrine\") and (e1_e2_combine not in del_relation_list):\n",
    "            fw2.write(json.dumps(line_dict) + \"\\n\")\n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  disease_anatomy 关系库\n",
    "\n",
    "import json\n",
    "\n",
    "with open('/home/chihui/chihui/jupyter/data/relationship_dict/all_relation_dict_file_v2.0/relation_dict_in_entity_dict/disease_anatomy_occur.dict','r') as file, \\\n",
    "    open('./disease_anatomy_del_data.txt','r') as fl, \\\n",
    "    open('./relation_dict_in_entity_dict_after_correct/disease_anatomy_occur.dict','w') as fw1, \\\n",
    "    open('./relation_dict_in_entity_dict_after_correct/symptom_anatomy_occur.dict','w') as fw2:\n",
    "    \n",
    "    correct_e1_cate_as_symptom = [\"prostate cancer aggressiveness quantitative trait locus on chromosome 19\",\"glioma susceptibility 1\", \\\n",
    "                            \"glioma susceptibility 4\",\"glioma susceptibility 5\",\"glioma susceptibility 6\",\"glioma susceptibility 8\", \\\n",
    "                            \"mental health wellness 1\",\"mental health wellness 2\"]\n",
    "    del_relation_list = []\n",
    "    fl.seek(0,0)\n",
    "    for line in fl:\n",
    "        del_relation = line.strip()\n",
    "        del_relation_list.append(del_relation)\n",
    "    \n",
    "    file.seek(0,0)\n",
    "    for line in file:\n",
    "        line_dict = json.loads(line.strip())\n",
    "        e1 = line_dict[\"e1\"]\n",
    "        e2 = line_dict[\"e2\"]\n",
    "        e1_e2_combine = e1 + \"####\" + e2\n",
    "        \n",
    "        if e1 in correct_e1_cate_as_symptom:\n",
    "            fw2.write(json.dumps(line_dict) + \"\\n\")\n",
    "        elif (e1 not in correct_e1_cate_as_symptom) and (e1_e2_combine not in del_relation_list):\n",
    "            fw1.write(json.dumps(line_dict) + \"\\n\")\n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  compound_protein 关系库\n",
    "\n",
    "import json\n",
    "\n",
    "with open('/home/chihui/chihui/jupyter/data/relationship_dict/all_relation_dict_file_v2.0/relation_dict_in_entity_dict/compound_protein_treat.dict','r') as file, \\\n",
    "    open('./compound_protein_del_data.txt','r') as fl, \\\n",
    "    open('./relation_dict_in_entity_dict_after_correct/compound_protein_treat.dict','w') as fw:\n",
    "    \n",
    "    del_relation_list = []\n",
    "    fl.seek(0,0)\n",
    "    for line in fl:\n",
    "        del_relation = line.strip()\n",
    "        del_relation_list.append(del_relation)\n",
    "    \n",
    "    file.seek(0,0)\n",
    "    for line in file:\n",
    "        line_dict = json.loads(line.strip())\n",
    "        source_list = line_dict[\"sources\"]\n",
    "        e1 = line_dict[\"e1\"]\n",
    "        e2 = line_dict[\"e2\"]\n",
    "        e1_e2_combine = e1 + \"####\" + e2\n",
    "        \n",
    "        if \"-4\" in source_list:   #  来源库为 drugbank\n",
    "            fw.write(json.dumps(line_dict) + \"\\n\")\n",
    "        elif (len(source_list) == 1) and (\"-10\" in source_list):   #  来源库为 ctd\n",
    "            fw.write(json.dumps(line_dict) + \"\\n\")\n",
    "        elif (len(source_list) == 1) and (\"-8\" in source_list) and (e1_e2_combine not in del_relation_list):\n",
    "            fw.write(json.dumps(line_dict) + \"\\n\")\n",
    "        elif (len(source_list) > 1) and (\"-8\" in source_list) and (\"-4\" not in source_list):\n",
    "            pubmedids = line_dict[\"pids\"]\n",
    "            if len(pubmedids) >= 1:\n",
    "                fw.write(json.dumps(line_dict) + \"\\n\")\n",
    "        elif (len(source_list) == 1) and ((\"-7\" in source_list) or (\"-3\" in source_list) or (\"-12\" in source_list) or (\"-9\" in source_list)):  #   chembl、dgidb、ebi、malacards\n",
    "            continue\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  protein_disease  关系库\n",
    "\n",
    "import json\n",
    "\n",
    "with open('/home/chihui/chihui/jupyter/data/relationship_dict/all_relation_dict_file_v2.0/relation_dict_in_entity_dict/protein_disease_cause.dict','r') as file, \\\n",
    "    open('./protein_disease_del_data.txt','r') as fl, \\\n",
    "    open('./relation_dict_in_entity_dict_after_correct/protein_disease_cause.dict','w') as fw:\n",
    "    \n",
    "    del_relation_list = []\n",
    "    fl.seek(0,0)\n",
    "    for line in fl:\n",
    "        del_relation = line.strip()\n",
    "        del_relation_list.append(del_relation)\n",
    "    \n",
    "    file.seek(0,0)\n",
    "    for line in file:\n",
    "        line_dict = json.loads(line.strip())\n",
    "        source_list = line_dict[\"sources\"]\n",
    "        e1 = line_dict[\"e1\"]\n",
    "        e2 = line_dict[\"e2\"]\n",
    "        e1_e2_combine = e1 + \"####\" + e2\n",
    "        \n",
    "        if (\"-9\" not in source_list) and (e1_e2_combine not in del_relation_list):\n",
    "            fw.write(json.dumps(line_dict) + \"\\n\")\n",
    "        elif (len(source_list) > 1) and (\"-9\" in source_list) and (e1_e2_combine not in del_relation_list):\n",
    "            fw.write(json.dumps(line_dict) + \"\\n\")\n",
    "        elif (len(source_list) == 1) and (\"-9\" in source_list):   #  malacards 来源库\n",
    "            pubmedids = line_dict[\"pids\"]\n",
    "            if len(pubmedids) >= 1:\n",
    "                fw.write(json.dumps(line_dict) + \"\\n\")\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  protein_protein  关系库\n",
    "\n",
    "import json\n",
    "\n",
    "with open('/home/chihui/chihui/jupyter/data/relationship_dict/all_relation_dict_file_v2.0/relation_dict_in_entity_dict/protein_protein_interact.dict','r') as file, \\\n",
    "    open('./protein_protein_del_data.txt','r') as fl, \\\n",
    "    open('./relation_dict_in_entity_dict_after_correct/protein_protein_interact.dict','w') as fw:\n",
    "\n",
    "    del_relation_list = []\n",
    "    fl.seek(0,0)\n",
    "    for line in fl:\n",
    "        del_relation = line.strip()\n",
    "        del_relation_list.append(del_relation)\n",
    "    \n",
    "    file.seek(0,0)\n",
    "    for line in file:\n",
    "        line_dict = json.loads(line.strip())\n",
    "        source_list = line_dict[\"sources\"]\n",
    "        e1 = line_dict[\"e1\"]\n",
    "        e2 = line_dict[\"e2\"]\n",
    "        e1_e2_combine = e1 + \"####\" + e2\n",
    "        \n",
    "        if e1 == e2:\n",
    "            continue\n",
    "        else:\n",
    "            if (len(source_list) == 1) and (\"-12\" in source_list):   #  仅来源于 ebi 库\n",
    "                pubmedids = line_dict[\"pids\"]\n",
    "                if len(pubmedids) >= 2:\n",
    "                    fw.write(json.dumps(line_dict) + \"\\n\")\n",
    "            else:\n",
    "                if (e1_e2_combine not in del_relation_list):\n",
    "                    fw.write(json.dumps(line_dict) + \"\\n\")\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  compound_disease  关系库\n",
    "\n",
    "import json\n",
    "\n",
    "with open('/home/chihui/chihui/jupyter/data/relationship_dict/all_relation_dict_file_v2.0/relation_dict_in_entity_dict/compound_disease_cause.dict','r') as file, \\\n",
    "    open('./compound_disease_del_data.txt','r') as fl, \\\n",
    "    open('./ctd_compound_disease_therapeutic_list.txt','r') as fr, \\\n",
    "    open('./relation_dict_in_entity_dict_after_correct/compound_disease_cause.dict','w') as fw:\n",
    "\n",
    "    del_relation_list = []\n",
    "    fl.seek(0,0)\n",
    "    for line in fl:\n",
    "        del_relation = line.strip()\n",
    "        del_relation_list.append(del_relation)\n",
    "    \n",
    "    ctd_compound_disease_therapeutic_list = []\n",
    "    fr.seek(0,0)\n",
    "    for line in fr:\n",
    "        compound_disease_combine = line.strip()\n",
    "        ctd_compound_disease_therapeutic_list.append(compound_disease_combine)\n",
    "        \n",
    "    file.seek(0,0)\n",
    "    for line in file:\n",
    "        line_dict = json.loads(line.strip())\n",
    "        source_list = line_dict[\"sources\"]\n",
    "        e1 = line_dict[\"e1\"]\n",
    "        e2 = line_dict[\"e2\"]\n",
    "        e1_e2_combine = e1 + \"####\" + e2\n",
    "        \n",
    "        if (e1_e2_combine in del_relation_list):\n",
    "            continue\n",
    "        elif (\"-4\" in source_list) or (\"-1\" in source_list) or (\"-9\" in source_list):   #  来源中有 drugbank、ttd、malacards\n",
    "            fw.write(json.dumps(line_dict) + \"\\n\")\n",
    "        elif (len(source_list) == 1) and (\"-10\" in source_list):   #  ctd\n",
    "            if e1_e2_combine in ctd_compound_disease_therapeutic_list:\n",
    "                fw.write(json.dumps(line_dict) + \"\\n\")\n",
    "        elif (len(source_list) == 1) and (\"-11\" in source_list):   #  biogrid、\n",
    "            pubmedids = line_dict[\"pids\"]\n",
    "            if len(pubmedids) >= 3:\n",
    "                fw.write(json.dumps(line_dict) + \"\\n\")\n",
    "        elif (len(source_list) == 1) and (\"-3\" in source_list):  #  来源为 dgidb\n",
    "            continue\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  drugs_disease  关系库\n",
    "\n",
    "import json\n",
    "\n",
    "with open('/home/chihui/chihui/jupyter/data/relationship_dict/all_relation_dict_file_v2.0/relation_dict_in_entity_dict/drugs_disease_treat.dict','r') as file, \\\n",
    "    open('./drugs_disease_del_data.txt','r') as fl, \\\n",
    "    open('./relation_dict_in_entity_dict_after_correct/drugs_disease_treat.dict','a') as fw:\n",
    "\n",
    "    del_relation_list = []\n",
    "    fl.seek(0,0)\n",
    "    for line in fl:\n",
    "        del_relation = line.strip()\n",
    "        del_relation_list.append(del_relation)\n",
    "\n",
    "    file.seek(0,0)\n",
    "    for line in file:\n",
    "        line_dict = json.loads(line.strip())\n",
    "        source_list = line_dict[\"sources\"]\n",
    "        e1 = line_dict[\"e1\"]\n",
    "        e2 = line_dict[\"e2\"]\n",
    "        e1_e2_combine = e1 + \"####\" + e2\n",
    "        \n",
    "        if (e1_e2_combine in del_relation_list):\n",
    "            continue\n",
    "        elif (\"-4\" in source_list):   #  drugbank 保留\n",
    "            fw.write(json.dumps(line_dict) + \"\\n\")\n",
    "        elif (len(source_list) == 1) and ((\"-11\" in source_list) or (\"-10\" in source_list)):\n",
    "            pubmedids = line_dict[\"pids\"]\n",
    "            if len(pubmedids) >= 3:\n",
    "                fw.write(json.dumps(line_dict) + \"\\n\")\n",
    "        elif (len(source_list) == 2) and (\"-8\" in source_list) and (\"-7\" in source_list):  #  drugcentral+chembl\n",
    "            if (e1_e2_combine not in del_relation_list):\n",
    "                fw.write(json.dumps(line_dict) + \"\\n\")\n",
    "        elif (len(source_list) == 2) and (\"-9\" in source_list) and (\"-10\" in source_list):  #  malacards+ctd\n",
    "            fw.write(json.dumps(line_dict) + \"\\n\")\n",
    "        elif (len(source_list) == 2) and (\"-1\" in source_list) and (\"-10\" in source_list):  #  ttd+ctd\n",
    "            fw.write(json.dumps(line_dict) + \"\\n\")\n",
    "        elif (len(source_list) == 2) and (\"-1\" in source_list) and (\"-9\" in source_list):   #  ttd+malacards\n",
    "            if (e1_e2_combine not in del_relation_list):\n",
    "                fw.write(json.dumps(line_dict) + \"\\n\")\n",
    "        elif (len(source_list) == 3) and (\"-1\" in source_list) and (\"-10\" in source_list) and (\"-9\" in source_list):  #  ttd+ctd+malacards\n",
    "            fw.write(json.dumps(line_dict) + \"\\n\")\n",
    "        elif (len(source_list) == 1) and ((\"-1\" in source_list) or (\"-9\" in source_list)):  #  ttd保留、malacards保留\n",
    "            fw.write(json.dumps(line_dict) + \"\\n\")\n",
    "        elif (len(source_list) == 1) and (\"-7\" in source_list):  #  chembl\n",
    "            continue\n",
    "        elif (len(source_list) == 1) and (\"-3\" in source_list):  #  dgidb\n",
    "            if (e1_e2_combine not in del_relation_list):\n",
    "                fw.write(json.dumps(line_dict) + \"\\n\")\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  gene_protein  关系库\n",
    "\n",
    "import json\n",
    "\n",
    "with open('/home/chihui/chihui/jupyter/data/relationship_dict/all_relation_dict_file_v2.0/relation_dict_in_entity_dict/gene_protein_express.dict','r') as file, \\\n",
    "    open('./gene_protein_del_data.txt','r') as fl, \\\n",
    "    open('./gene_protein_entity_cate_diff.txt','r') as fr, \\\n",
    "    open('./relation_dict_in_entity_dict_after_correct/gene_protein_express.dict','a') as fw1, \\\n",
    "    open('./relation_dict_in_entity_dict_after_correct/protein_protein_interact.dict','a') as fw2:\n",
    "    del_relation_list = []\n",
    "    fl.seek(0,0)\n",
    "    for line in fl:\n",
    "        del_relation = line.strip()\n",
    "        del_relation_list.append(del_relation)\n",
    "        \n",
    "    correct_e1_cate_as_protein = set()\n",
    "    fr.seek(0,0)\n",
    "    for line in fr:\n",
    "        entity = line.strip()\n",
    "        correct_e1_cate_as_protein.add(entity)\n",
    "    \n",
    "    file.seek(0,0)\n",
    "    for line in file:\n",
    "        line_dict = json.loads(line.strip())\n",
    "        source_list = line_dict[\"sources\"]\n",
    "        e1 = line_dict[\"e1\"]\n",
    "        e2 = line_dict[\"e2\"]\n",
    "        e1_e2_combine = e1 + \"####\" + e2\n",
    "        \n",
    "        if (e1_e2_combine in del_relation_list):\n",
    "            continue\n",
    "        elif (e1 in correct_e1_cate_as_protein):     #  e1 实体类别由 gene 改为 protein\n",
    "            fw2.write(json.dumps(line_dict) + \"\\n\")\n",
    "            continue\n",
    "        elif (\"-13\" in source_list) or (\"-6\" in source_list):  #  含有omim、uniprot的关系保留\n",
    "            fw1.write(json.dumps(line_dict) + \"\\n\")\n",
    "        elif (len(source_list) == 1) and (\"-12\" in source_list):  #  ebi保留            #   ebi来源的gene需要按规则分类调整为protein\n",
    "            fw1.write(json.dumps(line_dict) + \"\\n\")\n",
    "        else:\n",
    "            if (e1_e2_combine not in del_relation_list):\n",
    "                fw1.write(json.dumps(line_dict) + \"\\n\")\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  gene_gene 关系库\n",
    "\n",
    "import json\n",
    "\n",
    "with open('/home/chihui/chihui/jupyter/data/relationship_dict/all_relation_dict_file_v2.0/relation_dict_in_entity_dict/gene_gene_interact.dict','r') as file, \\\n",
    "    open('./gene_gene_del_data.txt','r') as fl, \\\n",
    "    open('./gene_gene_entity_cate_diff.txt','r') as fr, \\\n",
    "    open('./relation_dict_in_entity_dict_after_correct/gene_gene_interact.dict','a') as fw1, \\\n",
    "    open('./relation_dict_in_entity_dict_after_correct/gene_protein_express.dict','a') as fw2, \\\n",
    "    open('./relation_dict_in_entity_dict_after_correct/protein_protein_interact.dict','a') as fw3:\n",
    "    \n",
    "    del_relation_list = []\n",
    "    fl.seek(0,0)\n",
    "    for line in fl:\n",
    "        del_relation = line.strip()\n",
    "        del_relation_list.append(del_relation)\n",
    "    \n",
    "    correct_entity_cate_as_protein = set()\n",
    "    fr.seek(0,0)\n",
    "    for line in fr:\n",
    "        entity = line.strip()\n",
    "        correct_entity_cate_as_protein.add(entity)\n",
    "    \n",
    "    e1_e2_combine_list = set()\n",
    "    file.seek(0,0)\n",
    "    for line in file:\n",
    "        line_dict = json.loads(line.strip())\n",
    "        source_list = line_dict[\"sources\"]\n",
    "        e1 = line_dict[\"e1\"]\n",
    "        e2 = line_dict[\"e2\"]\n",
    "        e1_e2_combine = e1 + \"####\" + e2\n",
    "        e2_e1_combine = e2 = \"####\" + e1\n",
    "        \n",
    "        if (e1 == e2) or (e1_e2_combine in e1_e2_combine_list) or (e2_e1_combine in e1_e2_combine_list):\n",
    "            continue\n",
    "        else:\n",
    "            e1_e2_combine_list.add(e1_e2_combine)\n",
    "            e1_e2_combine_list.add(e2_e1_combine)\n",
    "            if (e1_e2_combine in del_relation_list):\n",
    "                continue\n",
    "            elif (e1 in correct_entity_cate_as_protein) and (e2 not in correct_entity_cate_as_protein):      #  e1 实体类别由 gene 改为 protein\n",
    "                line_dict[\"e1\"] = e2\n",
    "                line_dict[\"e2\"] = e1\n",
    "                fw2.write(json.dumps(line_dict) + \"\\n\")\n",
    "                continue\n",
    "            elif (e1 not in correct_entity_cate_as_protein) and (e2 in correct_entity_cate_as_protein):    #  e2 实体类别由 gene 改为 protein\n",
    "                fw2.write(json.dumps(line_dict) + \"\\n\")\n",
    "                continue\n",
    "            elif (e1 in correct_entity_cate_as_protein) and (e2 in correct_entity_cate_as_protein):   #  e1、e2 实体类别均由 gene 改为 protein\n",
    "                fw3.write(json.dumps(line_dict) + \"\\n\")\n",
    "                continue\n",
    "            elif (len(source_list) == 1) and (\"-11\" in source_list):  #  biogrid 保留pubmedid 大于等于 3 的数据\n",
    "                pubmedids = line_dict[\"pids\"]\n",
    "                if len(pubmedids) >= 3:\n",
    "                    fw1.write(json.dumps(line_dict) + \"\\n\")\n",
    "            elif (len(source_list) == 1) and (\"-12\" in source_list):  #  ebi 保留pubmedid 大于等于 2 的数据\n",
    "                pubmedids = line_dict[\"pids\"]\n",
    "                if len(pubmedids) >= 2:\n",
    "                    fw1.write(json.dumps(line_dict) + \"\\n\")\n",
    "            elif (len(source_list) == 1) and (\"-6\" in source_list):  #  uniprot全保留\n",
    "                fw1.write(json.dumps(line_dict) + \"\\n\")\n",
    "            elif (len(source_list) == 1) and (\"-13\" in source_list):  #  来源为 omim 的不要\n",
    "                continue\n",
    "            else:\n",
    "                if (e1_e2_combine not in del_relation_list):\n",
    "                    fw1.write(json.dumps(line_dict) + \"\\n\")\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  gene_anatomy 关系库\n",
    "\n",
    "import json\n",
    "\n",
    "with open('/home/chihui/chihui/jupyter/data/relationship_dict/all_relation_dict_file_v2.0/relation_dict_in_entity_dict/gene_anatomy_locate.dict','r') as file, \\\n",
    "    open('./gene_anatomy_del_data.txt','r') as fl, \\\n",
    "    open('./gene_anatomy_entity_cate_diff.txt','r') as fr, \\\n",
    "    open('./relation_dict_in_entity_dict_after_correct/gene_anatomy_locate.dict','a') as fw1, \\\n",
    "    open('./relation_dict_in_entity_dict_after_correct/protein_anatomy_belong.dict','a') as fw2:\n",
    "    \n",
    "    del_relation_list = []\n",
    "    fl.seek(0,0)\n",
    "    for line in fl:\n",
    "        del_relation = line.strip()\n",
    "        del_relation_list.append(del_relation)\n",
    "    \n",
    "    correct_e1_cate_as_protein = set()\n",
    "    fr.seek(0,0)\n",
    "    for line in fr:\n",
    "        entity = line.strip()\n",
    "        correct_e1_cate_as_protein.add(entity)\n",
    "    \n",
    "    file.seek(0,0)\n",
    "    for line in file:\n",
    "        line_dict = json.loads(line.strip())\n",
    "        source_list = line_dict[\"sources\"]\n",
    "        e1 = line_dict[\"e1\"]\n",
    "        e2 = line_dict[\"e2\"]\n",
    "        e1_e2_combine = e1 + \"####\" + e2\n",
    "        \n",
    "        if (e1_e2_combine in del_relation_list):\n",
    "            continue\n",
    "        elif (e1 in correct_e1_cate_as_protein):\n",
    "            fw2.write(json.dumps(line_dict) + \"\\n\")\n",
    "            continue\n",
    "        else:\n",
    "            if (e1_e2_combine not in del_relation_list):\n",
    "                fw1.write(json.dumps(line_dict) + \"\\n\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  compound_gene  关系库\n",
    "\n",
    "import json\n",
    "\n",
    "with open('/home/chihui/chihui/jupyter/data/relationship_dict/all_relation_dict_file_v2.0/relation_dict_in_entity_dict/compound_gene_treat.dict','r') as file, \\\n",
    "    open('./compound_gene_del_data.txt','r') as fl, \\\n",
    "    open('./compound_gene_entity_cate_diff.txt','r') as fr, \\\n",
    "    open('./relation_dict_in_entity_dict_after_correct/compound_gene_treat.dict','a') as fw1, \\\n",
    "    open('./relation_dict_in_entity_dict_after_correct/compound_protein_treat.dict','a') as fw2:\n",
    "\n",
    "    del_relation_list = []\n",
    "    fl.seek(0,0)\n",
    "    for line in fl:\n",
    "        del_relation = line.strip()\n",
    "        del_relation_list.append(del_relation)\n",
    "\n",
    "    correct_e2_cate_as_protein = set()\n",
    "    fr.seek(0,0)\n",
    "    for line in fr:\n",
    "        entity = line.strip()\n",
    "        correct_e2_cate_as_protein.add(entity)\n",
    "    \n",
    "    file.seek(0,0)\n",
    "    for line in file:\n",
    "        line_dict = json.loads(line.strip())\n",
    "        source_list = line_dict[\"sources\"]\n",
    "        e1 = line_dict[\"e1\"]\n",
    "        e2 = line_dict[\"e2\"]\n",
    "        e1_e2_combine = e1 + \"####\" + e2\n",
    "        \n",
    "        if (e1_e2_combine in del_relation_list):\n",
    "            continue\n",
    "        elif e2 in correct_e2_cate_as_protein:\n",
    "            fw2.write(json.dumps(line_dict) + \"\\n\")\n",
    "            continue\n",
    "        elif (len(source_list) == 1) and ((\"-11\" in source_list) or (\"-10\" in source_list)):   #  biogrid、ctd 保留pubmedID 大于等于 2 的数据         \n",
    "            pubmedids = line_dict[\"pids\"]\n",
    "            if len(pubmedids) >= 2:\n",
    "                fw1.write(json.dumps(line_dict) + \"\\n\")\n",
    "        elif (len(source_list) == 2) and (\"-10\" in source_list) and (\"-3\" in source_list):   #  ctd+dgidb 保留pubmedID 大于等于 2 的数据 \n",
    "            pubmedids = line_dict[\"pids\"]\n",
    "            if len(pubmedids) >= 2:\n",
    "                fw1.write(json.dumps(line_dict) + \"\\n\")\n",
    "        elif (len(source_list) == 1) and ((\"-7\" in source_list) or (\"-3\" in source_list)):  #  chembl、dgidb保留 pubmedID 大于等于 1 的数据\n",
    "            pubmedids = line_dict[\"pids\"]\n",
    "            if len(pubmedids) >= 1:\n",
    "                fw1.write(json.dumps(line_dict) + \"\\n\")\n",
    "        elif (len(source_list) == 1) and ((\"-4\" in source_list) or (\"-8\" in source_list)):   #  drugbank、drugcentral 全保留\n",
    "            fw1.write(json.dumps(line_dict) + \"\\n\")\n",
    "        elif (len(source_list) == 2) and (\"-8\" in source_list) and (\"-7\" in source_list):  #  drugcentral+chembl 全保留\n",
    "            fw1.write(json.dumps(line_dict) + \"\\n\")\n",
    "        elif (len(source_list) == 3) and (\"-8\" in source_list) and (\"-10\" in source_list) and (\"-3\" in source_list):   #  drugcentral+ctd+dgidb 全保留\n",
    "            fw1.write(json.dumps(line_dict) + \"\\n\")\n",
    "        elif (len(source_list) == 2) and (\"-8\" in source_list) and (\"-10\" in source_list):   #  drugcentral+ctd 不保留\n",
    "            continue\n",
    "        elif (len(source_list) == 2) and (\"-8\" in source_list) and (\"-3\" in source_list):   #  drugcentral+dgidb 不保留\n",
    "            continue\n",
    "        else:\n",
    "            if (e1_e2_combine not in del_relation_list):\n",
    "                fw1.write(json.dumps(line_dict) + \"\\n\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  drugs_protein  关系库\n",
    "\n",
    "import json\n",
    "\n",
    "with open('/home/chihui/chihui/jupyter/data/relationship_dict/all_relation_dict_file_v2.0/relation_dict_in_entity_dict/drugs_protein_target.dict','r') as file, \\\n",
    "    open('./drugs_protein_del_data.txt','r') as fl, \\\n",
    "    open('./relation_dict_in_entity_dict_after_correct/drugs_protein_target.dict','a') as fw:\n",
    "    \n",
    "    del_relation_list = []\n",
    "    fl.seek(0,0)\n",
    "    for line in fl:\n",
    "        del_relation = line.strip()\n",
    "        del_relation_list.append(del_relation)\n",
    "        \n",
    "    file.seek(0,0)\n",
    "    for line in file:\n",
    "        line_dict = json.loads(line.strip())\n",
    "        source_list = line_dict[\"sources\"]\n",
    "        e1 = line_dict[\"e1\"]\n",
    "        e2 = line_dict[\"e2\"]\n",
    "        e1_e2_combine = e1 + \"####\" + e2\n",
    "\n",
    "        if (len(source_list) == 1) and (\"-8\" in source_list):   #  drugcentral 全保留\n",
    "            fw.write(json.dumps(line_dict) + \"\\n\")\n",
    "        elif (len(source_list) == 2) and (\"-11\" in source_list) and (\"-4\" in source_list):  #  biogrid+drugbank 全保留\n",
    "            fw.write(json.dumps(line_dict) + \"\\n\")\n",
    "        elif (len(source_list) == 2) and (\"-7\" in source_list) and (\"-4\" in source_list):  #  chembl+drugbank 全保留\n",
    "            fw.write(json.dumps(line_dict) + \"\\n\")\n",
    "        elif (len(source_list) == 2) and (\"-8\" in source_list) and (\"-4\" in source_list):  #  drugcentral+drugbank 全保留\n",
    "            fw.write(json.dumps(line_dict) + \"\\n\")\n",
    "        elif (len(source_list) == 3) and (\"-7\" in source_list) and (\"-11\" in source_list) and (\"-4\" in source_list):  #  chembl+biogrid+drugbank 全保留\n",
    "            fw.write(json.dumps(line_dict) + \"\\n\")\n",
    "        elif (len(source_list) == 3) and (\"-8\" in source_list) and (\"-3\" in source_list) and (\"-4\" in source_list):  #  drugcentral+dgidb+drugbank 全保留\n",
    "            fw.write(json.dumps(line_dict) + \"\\n\")\n",
    "        elif (len(source_list) == 4) and (\"-8\" in source_list) and (\"-3\" in source_list) and (\"-7\" in source_list) and (\"-4\" in source_list):  #  drugcentral+dgidb+chembl+drugbank 全保留\n",
    "            fw.write(json.dumps(line_dict) + \"\\n\")\n",
    "        elif (len(source_list) == 1) and ((\"-7\" in source_list) or (\"-3\" in source_list) or (\"-4\" in source_list)):  #  chembl、dgidb、drugbank 保留pubmedID 大于等于1的\n",
    "            pubmedids = line_dict[\"pids\"]\n",
    "            if len(pubmedids) >= 1:\n",
    "                fw.write(json.dumps(line_dict) + \"\\n\")\n",
    "        elif (len(source_list) == 2) and (\"-8\" in source_list) and (\"-7\" in source_list):  #  drugcentral+chembl 保留pubmedID 大于等于1的数据\n",
    "            pubmedids = line_dict[\"pids\"]\n",
    "            if len(pubmedids) >= 1:\n",
    "                fw.write(json.dumps(line_dict) + \"\\n\")\n",
    "        else:\n",
    "            if (e1_e2_combine not in del_relation_list):\n",
    "                fw.write(json.dumps(line_dict) + \"\\n\")\n",
    "                \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  gene_disease  关系库\n",
    "\n",
    "import json\n",
    "\n",
    "with open('/home/chihui/chihui/jupyter/data/relationship_dict/all_relation_dict_file_v2.0/relation_dict_in_entity_dict/gene_disease_cause.dict','r') as file, \\\n",
    "    open('./gene_disease_del_data.txt','r') as fl, \\\n",
    "    open('./gene_disease_entity_cate_diff.txt','r') as fr, \\\n",
    "    open('./relation_dict_in_entity_dict_after_correct/gene_disease_cause.dict','a') as fw1, \\\n",
    "    open('./relation_dict_in_entity_dict_after_correct/protein_disease_cause.dict','a') as fw2:\n",
    "\n",
    "    del_relation_list = []\n",
    "    fl.seek(0,0)\n",
    "    for line in fl:\n",
    "        del_relation = line.strip()\n",
    "        del_relation_list.append(del_relation)\n",
    "\n",
    "    correct_e1_cate_as_protein = set()\n",
    "    fr.seek(0,0)\n",
    "    for line in fr:\n",
    "        entity = line.strip()\n",
    "        correct_e1_cate_as_protein.add(entity)\n",
    "     \n",
    "    file.seek(0,0)\n",
    "    for line in file:\n",
    "        line_dict = json.loads(line.strip())\n",
    "        source_list = line_dict[\"sources\"]\n",
    "        e1 = line_dict[\"e1\"]\n",
    "        e2 = line_dict[\"e2\"]\n",
    "        e1_e2_combine = e1 + \"####\" + e2\n",
    "        \n",
    "        if (e1_e2_combine in del_relation_list):\n",
    "            continue\n",
    "        elif (e1 in correct_e1_cate_as_protein):\n",
    "            fw2.write(json.dumps(line_dict) + \"\\n\")\n",
    "            continue\n",
    "        elif (len(source_list) == 1) and ((\"-2\" in source_list) or (\"-1\" in source_list)):   #  kegg、ttd 全保留\n",
    "            fw1.write(json.dumps(line_dict) + \"\\n\")\n",
    "        elif (len(source_list) == 2) and (\"-9\" in source_list) and (\"-2\" in source_list):   #  malacards+kegg 全保留\n",
    "            fw1.write(json.dumps(line_dict) + \"\\n\")\n",
    "        elif (len(source_list) == 1) and (\"-11\" in source_list):  #  biogrid 不保留\n",
    "            continue\n",
    "        elif (len(source_list) == 1) and (\"-9\" in source_list):  #  malacards 保留 pubmedID 大于等于1的数据\n",
    "            pubmedids = line_dict[\"pids\"]\n",
    "            if len(pubmedids) >= 1:\n",
    "                fw1.write(json.dumps(line_dict) + \"\\n\")\n",
    "        else:\n",
    "            if (e1_e2_combine not in del_relation_list):\n",
    "                fw1.write(json.dumps(line_dict) + \"\\n\")\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  drugs_gene 关系库\n",
    "\n",
    "import json\n",
    "\n",
    "with open('/home/chihui/chihui/jupyter/data/relationship_dict/all_relation_dict_file_v2.0/relation_dict_in_entity_dict/drugs_gene_target.dict','r') as file, \\\n",
    "    open('./drugs_gene_del_data.txt','r') as fl, \\\n",
    "    open('./drugs_gene_entity_cate_diff.txt','r') as fr, \\\n",
    "    open('./relation_dict_in_entity_dict_after_correct/drugs_gene_target.dict','a') as fw1, \\\n",
    "    open('./relation_dict_in_entity_dict_after_correct/drugs_protein_target.dict','a') as fw2:\n",
    "\n",
    "    del_relation_list = []\n",
    "    fl.seek(0,0)\n",
    "    for line in fl:\n",
    "        del_relation = line.strip()\n",
    "        del_relation_list.append(del_relation)\n",
    "\n",
    "    correct_e2_cate_as_protein = set()\n",
    "    fr.seek(0,0)\n",
    "    for line in fr:\n",
    "        entity = line.strip()\n",
    "        correct_e2_cate_as_protein.add(entity)\n",
    "\n",
    "    file.seek(0,0)\n",
    "    for line in file:\n",
    "        line_dict = json.loads(line.strip())\n",
    "        source_list = line_dict[\"sources\"]\n",
    "        e1 = line_dict[\"e1\"]\n",
    "        e2 = line_dict[\"e2\"]\n",
    "        e1_e2_combine = e1 + \"####\" + e2\n",
    "        \n",
    "        if (e1_e2_combine in del_relation_list):\n",
    "            continue\n",
    "        elif e2 in correct_e2_cate_as_protein:\n",
    "            fw2.write(json.dumps(line_dict) + \"\\n\")\n",
    "            continue\n",
    "# 含有 drugbank、biogrid+ctd+dgidb、ctd+dgidb、drugcentral+ctd+dgidb、drugcentral+biogrid+ctd+dgidb 全保留\n",
    "# drugcentral+biogrid+ctd、drugcentral+biogrid+dgidb、drugcentral+biogrid、drugcentral+chembl+biogrid+ctd 全保留\n",
    "# drugcentral+chembl+biogrid、drugcentral+chembl+ctd+dgidb、drugcentral+chembl+ctd、drugcentral、malacards 全保留\n",
    "        elif (\"-4\" in source_list) or (source_list == ['-11', '-10', '-3']) or (source_list == ['-10', '-3']) or (source_list == ['-8', '-10', '-3']) \\\n",
    "            or (source_list == ['-8', '-11', '-10', '-3']) or (source_list == ['-8', '-11', '-10']) or (source_list == ['-8', '-11', '-3']) \\\n",
    "            or (source_list == ['-8', '-11']) or (source_list == ['-8', '-7', '-11', '-10']) or (source_list == ['-8', '-7', '-11']) \\\n",
    "            or (source_list == ['-8', '-7', '-10', '-3']) or (source_list == ['-8', '-7', '-10']) or (source_list == ['-8']) or (source_list == ['-9']):\n",
    "            fw1.write(json.dumps(line_dict) + \"\\n\")\n",
    "# biogrid+ctd、biogrid+dgidb、biogrid、ctd 保留 pubmedID 大于等于2的数据\n",
    "        elif (source_list == ['-11', '-10']) or (source_list == ['-11', '-3']) or (source_list == ['-11']) or (source_list == ['-10']):\n",
    "            pubmedids = line_dict[\"pids\"]\n",
    "            if len(pubmedids) >= 2:\n",
    "                fw1.write(json.dumps(line_dict) + \"\\n\")\n",
    "# chembl、dgidb、drugcentral+chembl、drugcentral+dgidb 保留 pubmedID 大于等于1的数据\n",
    "        elif (source_list == ['-7']) or (source_list == ['-3']) or (source_list == ['-8', '-7']) or (source_list == ['-8', '-3']):\n",
    "            pubmedids = line_dict[\"pids\"]\n",
    "            if len(pubmedids) >= 1:\n",
    "                fw1.write(json.dumps(line_dict) + \"\\n\")\n",
    "# drugcentral+ctd 保留 pubmedID 大于等于3的数据\n",
    "        elif (source_list == ['-8', '-10']):\n",
    "            pubmedids = line_dict[\"pids\"]\n",
    "            if len(pubmedids) >= 3:\n",
    "                fw1.write(json.dumps(line_dict) + \"\\n\")\n",
    "        else:\n",
    "            if (e1_e2_combine not in del_relation_list):\n",
    "                fw1.write(json.dumps(line_dict) + \"\\n\")\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-11', '-10', '-3']\n",
      "['-11', '-10', '-3']\n",
      "['-11', '-10', '-3']\n",
      "['-11', '-10', '-3']\n",
      "['-11', '-10', '-3']\n",
      "['-11', '-10', '-3']\n",
      "['-11', '-10', '-3']\n",
      "['-11', '-10', '-3']\n",
      "['-11', '-10', '-3']\n",
      "['-11', '-10', '-3']\n",
      "['-11', '-10', '-3']\n",
      "['-11', '-10', '-3']\n",
      "['-11', '-10', '-3']\n",
      "['-11', '-10', '-3']\n",
      "['-11', '-10', '-3']\n",
      "['-11', '-10', '-3']\n",
      "['-11', '-10', '-3']\n",
      "['-11', '-10', '-3']\n",
      "['-11', '-10', '-3']\n",
      "['-11', '-10', '-3']\n",
      "['-11', '-10', '-3']\n",
      "['-11', '-10', '-3']\n",
      "['-11', '-10', '-3']\n",
      "['-11', '-10', '-3']\n",
      "['-11', '-10', '-3']\n",
      "['-11', '-10', '-3']\n",
      "['-11', '-10', '-3']\n",
      "['-11', '-10', '-3']\n",
      "['-11', '-10', '-3']\n",
      "['-11', '-10', '-3']\n",
      "['-11', '-10', '-3']\n",
      "['-11', '-10', '-3']\n",
      "['-11', '-10', '-3']\n",
      "['-11', '-10', '-3']\n",
      "['-11', '-10', '-3']\n",
      "['-11', '-10', '-3']\n",
      "['-11', '-10', '-3']\n",
      "['-11', '-10', '-3']\n",
      "['-11', '-10', '-3']\n",
      "['-11', '-10', '-3']\n",
      "['-11', '-10', '-3']\n",
      "['-11', '-10', '-3']\n",
      "['-11', '-10', '-3']\n",
      "['-11', '-10', '-3']\n",
      "['-11', '-10', '-3']\n",
      "['-11', '-10', '-3']\n",
      "['-11', '-10', '-3']\n",
      "['-11', '-10', '-3']\n",
      "['-11', '-10', '-3']\n",
      "['-11', '-10', '-3']\n"
     ]
    }
   ],
   "source": [
    "#  test\n",
    "\n",
    "import json\n",
    "with open('/home/chihui/chihui/jupyter/data/relationship_dict/all_relation_dict_file_v2.0/relation_dict_in_entity_dict/drugs_gene_target.dict','r') as file:\n",
    "    \n",
    "    file.seek(0,0)\n",
    "    num = 0\n",
    "    for line in file:\n",
    "#        print(num)\n",
    "        line_dict = json.loads(line.strip())\n",
    "        source_list = line_dict[\"sources\"]\n",
    "        if (source_list == ['-11', '-10', '-3']):\n",
    "            num += 1\n",
    "            print(source_list)\n",
    "        if num >= 20:\n",
    "            break\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
